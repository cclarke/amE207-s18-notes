{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility or Risk - Back to Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to original AM 207 course staff notes: https://am207.github.io/2018spring/wiki/utilityorrisk.html#the-logarithmic-utility-function-and-probabilistic-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Basic idea behind decision theory is that **predictions** (or **actions absed on predictions**) are **described by a utility or loss function**, whose values can be **computed given the observed data**.\n",
    "* Key distributions in the Bayesian scenario (our scenarios of interest)\n",
    "    * **posterior**: $p(\\theta | D)$\n",
    "    * **posterior predictive**: $p(y^* | D) = \\int p(y^* | \\theta) \\ p(\\theta | D) \\ d\\theta $   \n",
    "* Components of the decision scenario:\n",
    "    1. $a \\in A$, an **action** from a **set of available actions** for the decision problem\n",
    "    2. $\\omega \\in \\Omega$, a **state** in the **set of states in the world**\n",
    "        * In our scenario, $\\omega$ could be either $y^*$ or $\\theta$, depending on the problem at hand\n",
    "    3. $p(\\omega | D)$, our **current belieft about the world**.\n",
    "        * in practice, can be either the prosterior distribution or the posterior predictive distribution\n",
    "    4. a **utility function** $u(a, \\omega) : A \\times \\Omega \\rightarrow \\mathbb{R}$. Ths function **awards a utility to each action $a$, when the state of the world is $\\omega$**\n",
    "* the goal is to **maximize the distribution expected utility $\\bar{u}(a)$ over all possible actions**\n",
    "    * $\\bar{u}(a) = \\int u(a, \\omega) \\ p(\\omega | D) \\ d\\omega$\n",
    "    * so we want to find $\\hat{a} = \\underset{a}{\\arg\\max } \\ \\bar{u}(a)$ â€” the **bayes action**\n",
    "* the maximum expected utility is then given by $\\bar{u}(\\hat{a}, p) = \\bar{u}(\\hat{a})$\n",
    "* we define a **divergence** quanitity $d(a, p) = \\bar{u}(p, p) - \\bar{u}(a, p)$\n",
    "    * so, **one can think of minimizing $d(a, p)$ with respect to $a$ as a way to get $\\hat{a}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk from the Posterior Predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* consider the case where $\\omega = y^*$, and we have a model $M$ with respect to which we can define a posterior predictive distribution. Then we can condition on this model in the expressions for $\\bar{u}(a)$ and $\\bar{u}(\\hat{a}, p)$ as follows:\n",
    "\n",
    "$$\\bar{u}(a) = \\int u(a, y^*) \\ p(y^* | D, M) \\ dy^*,$$\n",
    "$$\\bar{u}(\\hat{a}, p) = \\bar{u}(\\hat{a}) = \\int u(\\hat{a}, y^*) \\ p(y^* | D, M) \\ dy^*$$\n",
    "\n",
    "* can make $a$ a function of $x$ as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The squared error loss/utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* squared error loss is an examole of a risk **defined to make a point estimate**\n",
    "* (I like this, quoted directly: \"Given a posterior predictive distribution, **how do you commmunicate one number to your boss from it?**\")\n",
    "* define squared error loss on of an action, given a predicted value: $$l(a, y^*) = (a - y^*)^2$$\n",
    "* Expression for **expected loss**: $$\\bar{l}(a) = \\int (a - y^*)^2 \\ p(y^* \\mid D, M) \\ dy^*$$\n",
    "* The point that minimizes this expected loss is $$\\hat{a} = E_p[y^*]$$\n",
    "    * Then, the **expected loss just becomes $Var_p[y^*]$** (just plog $\\hat{a} = E_p[y^*]$ in to the equation for expected loss and follow the calculations through)\n",
    "* (course staff lecture notes make the claim that \"Using such a loss thus indicates that you only care about the first two moments about the distribution, and that there is no gain to considering things like skewness and kurtosis\"... **think about just why this is the case**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Logarithmic Utility Function and Probabilistic Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **logarithmic utility function** is used for probabilistic prediction when the **unknown state is a future observation $y^*$**\n",
    "    * goal is to use this utility function to find the distribution of the future observations\n",
    "* logarithmic utility function is $$u(a, y^*) = log \\ a(y^*)$$\n",
    "* expected utility is as expected\n",
    "* the $a$ that maximizes expected utility is just the posterior predictive distribuiton: $$\\hat{a}(y^*) = p(y^* \\mid D, M)$$\n",
    "* the maximized utility is then just the **negative entropy of the posterior predictive distribution**: $$\\bar{u}(\\hat{a}) = \\int \\log(p(y^* \\mid D, M)) \\ p(y^* \\mid D, M) \\ dy^*$$\n",
    "    * then the divergence in this case is just the **KL divergence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single prediction vs. multiple prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the context above is akin to trying to predict the marginal predictive distribution\n",
    "* theoretical derivation is the same for the joint distribution: \"consider the joint to be derived step by step from updated posterior predictives, as the new data points 'come in'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions with respect to which model/distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When our goal is to compare models, we can do so without knowing the **\"true model\"**: \"This is the essential idea behind taking the difference in the KL divergences (or divergences of another kind) which allow us to **create a relative scale on which quantities like DIC or WAIC can be compared**\"\n",
    "* define a **generalization utility**: $$\\bar{u}_t(\\hat{a}) = \\int u(\\hat{a}, y^*) \\ p_t(y^*) \\ dy^*$$\n",
    "    * $p_t(y^*)$ is the true predictive distribution.\n",
    "    * use $\\hat{a}$ since we're already considering the action as optimal w.r.t. a model's posterior predictive\n",
    "* **True belief distribution**: not included int these notes, but see [Vehtari and Ojanen (2012)](https://projecteuclid.org/euclid.ssu/1356628931) for an exposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian model averaging\n",
    "\n",
    "[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where are the models?\n",
    "\n",
    "[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* key thing here is that we will **sort our average utilities in some order\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk from the Posterior: Posterior Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
