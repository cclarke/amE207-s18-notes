{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility or Risk - Back to Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Basic idea behind decision theory is that **predictions** (or **actions absed on predictions**) are **described by a utility or loss function**, whose values can be **computed given the observed data**.\n",
    "* Key distributions in the Bayesian scenario (our scenarios of interest)\n",
    "    * **posterior**: $p(\\theta | D)$\n",
    "    * **posterior predictive**: $p(y^* | D) = \\int p(y^* | \\theta) \\ p(\\theta | D) \\ d\\theta $   \n",
    "* Components of the decision scenario:\n",
    "    1. $a \\in A$, an **action** from a **set of available actions** for the decision problem\n",
    "    2. $\\omega \\in \\Omega$, a **state** in the **set of states in the world**\n",
    "        * In our scenario, $\\omega$ could be either $y^*$ or $\\theta$, depending on the problem at hand\n",
    "    3. $p(\\omega | D)$, our **current belieft about the world**.\n",
    "        * in practice, can be either the prosterior distribution or the posterior predictive distribution\n",
    "    4. a **utility function** $u(a, \\omega) : A \\times \\Omega \\rightarrow \\mathbb{R}$. Ths function **awards a utility to each action $a$, when the state of the world is $\\omega$**\n",
    "* the goal is to **maximize the distribution expected utility $\\bar{u}(a)$ over all possible actions**\n",
    "    * $\\bar{u}(a) = \\int u(a, \\omega) \\ p(\\omega | D) \\ d\\omega$\n",
    "    * so we want to find $\\hat{a} = \\underset{a}{\\arg\\max } \\ \\bar{u}(a)$ â€” the **bayes action**\n",
    "* the maximum expected utility is then given by $\\bar{u}(\\hat{a}, p) = \\bar{u}(\\hat{a})$\n",
    "* we define a **divergence** quanitity $d(a, p) = \\bar{u}(p, p) - \\bar{u}(a, p)$\n",
    "    * so, **one can think of minimizing $d(a, p)$ with respect to $a$ as a way to get $\\hat{a}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk from the Posterior Predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* consider the case where $\\omega = y^*$, and we have a model $M$ with respect to which we can define a posterior predictive distribution. Then we can condition on this model in the expressions for $\\bar{u}(a)$ and $\\bar{u}(\\hat{a}, p)$ as follows:\n",
    "\n",
    "$$\\bar{u}(a) = \\int u(a, y^*) \\ p(y^* | D, M) \\ dy^*,$$\n",
    "$$\\bar{u}(\\hat{a}, p) = \\bar{u}(\\hat{a}) = \\int u(\\hat{a}, y^*) \\ p(y^* | D, M) \\ dy^*$$\n",
    "\n",
    "* can make $a$ a function of $x$ as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
